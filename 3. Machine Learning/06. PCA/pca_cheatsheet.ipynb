{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Personal Cheat Sheet\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\r\n",
    "\r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data from wine dataset\r\n",
    "- 13 columns containing infos\r\n",
    "\r\n",
    "![image](wine_column_info.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Data\r\n",
    "\r\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\r\n",
    "\r\n",
    "df = pd.read_csv(data_url, header=None)\r\n",
    "\r\n",
    "df.shape\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3     4    5     6     7     8     9      10    11  \\\n",
       "0     1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1     1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2     1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3     1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4     1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..   ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
       "173   3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174   3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175   3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176   3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177   3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       12    13  \n",
       "0    3.92  1065  \n",
       "1    3.40  1050  \n",
       "2    3.17  1185  \n",
       "3    3.45  1480  \n",
       "4    2.93   735  \n",
       "..    ...   ...  \n",
       "173  1.74   740  \n",
       "174  1.56   750  \n",
       "175  1.56   835  \n",
       "176  1.62   840  \n",
       "177  1.60   560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y\r\n",
    "# X is ALL VARIABLES\r\n",
    "# Y is the LABEL\r\n",
    "# This is for supervised learning\r\n",
    "\r\n",
    "X, Y = df.iloc[:,1:], df.iloc[:,0]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data\r\n",
    "#REMEMBER, SPLIT FIRST BEFORE NORMALIZING\r\n",
    "\r\n",
    "#stratify is so that the in train set, the distribution of values is the same\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, stratify = Y, random_state = 0)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize the Data\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "X_train_scaled = scaler.fit_transform(X_train)\r\n",
    "X_test_scaled = scaler.transform(X_test)\r\n",
    "\r\n",
    "X_test_scaled.shape\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      13.033548\n",
       "2       2.353790\n",
       "3       2.384919\n",
       "4      19.801613\n",
       "5      99.088710\n",
       "6       2.324839\n",
       "7       2.064113\n",
       "8       0.368065\n",
       "9       1.640887\n",
       "10      5.089597\n",
       "11      0.954194\n",
       "12      2.619355\n",
       "13    754.822581\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the mean for X_train\r\n",
    "\r\n",
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the mean of the normalized data\r\n",
    "#if not in dataframe, it will average everything. Since it was an array\r\n",
    "\r\n",
    "#df2 = pd.DataFrame(X_train_scaled)\r\n",
    "#df2\r\n",
    "#np.mean(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Covariance\r\n",
    "\r\n",
    "covariance_matrix = np.cov(X_train_scaled.T) # <-- The Transpose is important, as np.cov normally uses rows as feature identification\r\n",
    "\r\n",
    "covariance_matrix.shape\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.84274532, 2.41602459, 1.54845825, 0.96120438, 0.84166161,\n",
       "       0.6620634 , 0.51828472, 0.34650377, 0.3131368 , 0.10754642,\n",
       "       0.21357215, 0.15362835, 0.1808613 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing Eigenvalues and Eigenvectors\r\n",
    "\r\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\r\n",
    "\r\n",
    "eigenvalues # <-- is the lambda, the one which is multiplied by x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13724218,  0.24724326, -0.02545159,  0.20694508, -0.15436582,\n",
       "       -0.39376952, -0.41735106,  0.30572896, -0.30668347,  0.07554066,\n",
       "       -0.32613263, -0.36861022, -0.29669651])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors[:,0] # <--- choose the rows first, the the column. This is the first eigenvector\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6646289 ,  1.19733616, -0.12325558,  1.00218234, -0.74755436,\n",
       "       -1.90692551, -2.02112491,  1.48056749, -1.48518993,  0.36582417,\n",
       "       -1.57937726, -1.78508543, -1.43682565])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if the two multiplication is the same\r\n",
    "\r\n",
    "eigenvalues[0] * eigenvectors[:,0]\r\n",
    "\r\n",
    "np.dot(covariance_matrix, eigenvectors[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6646289 ,  1.19733616, -0.12325558,  1.00218234, -0.74755436,\n",
       "       -1.90692551, -2.02112491,  1.48056749, -1.48518993,  0.36582417,\n",
       "       -1.57937726, -1.78508543, -1.43682565])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues[0] * eigenvectors[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.21534439,  0.39833285,  0.59087448, -0.27428896,  0.70003148,\n",
       "        0.12273656, -0.05526265,  0.21862328,  0.02017943,  1.32827186,\n",
       "       -0.50051411, -0.60165138,  0.91864363])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd Testing\r\n",
    "np.dot(covariance_matrix, eigenvectors[:,1])\r\n",
    "#eigenvalues[1] * eigenvectors[:,1]\r\n",
    "\r\n",
    "#PROVEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Explained Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\lambda_{i}}{\\sum_{i}^{d}\\lambda_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.9514686 , 18.43492706, 11.81515909,  7.33425176,  6.42210782,\n",
       "        5.05172448,  3.95465389,  2.64391832,  2.38931926,  1.62961377,\n",
       "        1.38002112,  1.17222624,  0.82060857])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = sum(eigenvalues)\r\n",
    "\r\n",
    "#Notice the for loop for below\r\n",
    "variance_explained = [(eig_val/tot)\r\n",
    "                        for eig_val in sorted(eigenvalues, reverse=True)]\r\n",
    "\r\n",
    "#The represents how many percentages of variance for each variable is described\r\n",
    "np.array(variance_explained)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36951469, 0.55386396, 0.67201555, 0.74535807, 0.80957914,\n",
       "       0.86009639, 0.89964293, 0.92608211, 0.9499753 , 0.96627144,\n",
       "       0.98007165, 0.99179391, 1.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_variance_explained = np.cumsum(variance_explained)\r\n",
    "\r\n",
    "cum_variance_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f6044b41c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot in a histogram\r\n",
    "\r\n",
    "plt.bar(range(1,14), variance_explained, alpha = 0.5, align= 'center', label=\"individual explained variance\")\r\n",
    "plt.step(range(1,14), cum_variance_explained, where= 'mid', label = 'cumulative explained variance')\r\n",
    "plt.ylabel('Explained Variance Ratio')\r\n",
    "plt.xlabel('Principal Component Index')\r\n",
    "plt.legend('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "850c152f8f84f3548ed5f09fd834180be13dced819bcdf283d955f3afcab8cf5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}